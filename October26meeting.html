<!DOCTYPE html>
<html>
<head>
    <title>Ethics of AI Society of Waterloo</title>

    <style>
        body {
            background-color: #232A44;
            color: white;
            font-family: Arial, sans-serif;
            text-align: left;
        }

        a {
            color: #A9C7FF;
        }

        table {
    width: 40%;
    border-collapse: collapse;
}

td, th {
    border: 1px solid #ccc;
    padding: 10px;
    vertical-align: top;
}

th {
    background-color: #000000;
    text-align: left;
}

.section-header {
    background-color: #cc0000;
    font-weight: bold;
    font-size: 1.1em;
}

.meta {
    background-color: #232A44;
}

ul {
    margin-top: 5px;
}
</style>
   
</head>

<body>
<center>

<a href="https://eaisow.github.io/ethicsofaisociety/">
    <img src="images/eais.png" width="700"></center>
</a>
    
    

    <p>
Previous Meetings
    </p>


</head>

<body>

<table>

<tr>
<h1>Briefing Notes – Ethics of AI Society Meeting</h1>

<div class="meta">
<p>
<strong>Date:</strong> October 26, 2023<br>
<strong>Duration:</strong> 1h 12m<br>
<strong>Facilitator:</strong> Dr. Matthew Steven William Silk
</p>
</div>

<div class="section-title">1. Purpose of Meeting</div>
<ul>
<li>Explore ethical, practical, and governance issues surrounding AI.</li>
<li>Discuss implications for academia, research, and society.</li>
<li>Plan next meeting and potential symposium.</li>
</ul>


<div class="section-title">2. Key Decisions & Action Items</div>

<p><strong>Next Meeting:</strong></p>
<ul>
<li>Date: November 16, 2023, at 3:00 PM.</li>
<li>Location: Same meeting room as current session.</li>
</ul>

<p><strong>Potential Symposium:</strong></p>
<ul>
<li>Consider a one-day event with invited speakers in November or later.</li>
</ul>

<p><strong>Action:</strong></p>
<ul>
<li>Matthew to confirm room booking and share symposium updates.</li>
<li>Participants to propose topics for next meeting via Teams.</li>
</ul>


<div class="section-title">3. Discussion Highlights</div>

<p><strong>A. Introductions & Interests</strong></p>
<ul>
<li>Participants include faculty, librarians, teaching support staff, data scientists, and students.</li>
<li>
Key interests:
    <ul>
        <li>Ethics of belief and responsibility in AI use.</li>
        <li>Data governance and bias in datasets.</li>
        <li>Hidden labor in AI systems (e.g., content moderation).</li>
        <li>Impact on teaching and research integrity.</li>
    </ul>
</li>
</ul>

<p><strong>B. Natural vs. Artificial Intelligence</strong></p>
<ul>
<li>Example: Bees trained to detect explosives combined with AI monitoring.</li>
<li>Concern: Over-reliance on AI may overshadow natural intelligence and human judgment.</li>
</ul>

<p><strong>C. Hidden Labor & Data Labeling</strong></p>
<ul>
<li>Workers labeling harmful content face severe mental health risks.</li>
<li>Outsourcing to low-cost labor markets raises ethical concerns.</li>
<li>Some workers use AI to automate labeling, risking data quality.</li>
</ul>

<p><strong>D. Data Poisoning</strong></p>
<ul>
<li>Technique: Altering pixels invisibly to mislead ML models.</li>
<li>
Risks:
    <ul>
        <li>Protecting intellectual property vs. malicious sabotage.</li>
        <li>Misuse in critical domains (e.g., medical imaging).</li>
    </ul>
</li>
<li>Ethical dilemma: Potential market for “poisoning services.”</li>
</ul>

<p><strong>E. Governance & Informed Consent</strong></p>
<ul>
<li>AI development outpaces policy.</li>
<li>
Academic concerns:
    <ul>
        <li>Students required to submit work to plagiarism tools (e.g., Turnitin).</li>
        <li>Limited transparency on student data usage.</li>
    </ul>
</li>
<li>Broader question: Who ensures accountability and consent in data use?</li>
</ul>

<p><strong>F. AI in Peer Review & Grading</strong></p>
<p><strong>Pros:</strong></p>
<ul>
<li>Speed and scalability.</li>
<li>Potential diversity of feedback.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
<li>Algorithms cannot evaluate originality.</li>
<li>Risk of bias and opacity.</li>
</ul>

<p><strong>Suggested Role:</strong> AI as supplementary tool; human editors retain oversight.</p>

<p><strong>G. Broader Ethical Concerns</strong></p>
<ul>
<li><strong>Opacity & Accountability:</strong> Hidden biases may evade detection.</li>
<li><strong>Manipulation Risks:</strong> Systematic influence at scale.</li>
<li><strong>Cultural Impact:</strong> Generative AI blurs authenticity (e.g., AI-generated Oasis album).</li>
<li><strong>Historical Parallel:</strong> Compared to nuclear technology—difficult to contain once developed.</li>
</ul>


<div class="section-title">4. Emerging Themes</div>
<ul>
<li><strong>Transparency & Explainability:</strong> Essential for trust.</li>
<li><strong>Human Oversight:</strong> Critical in high-stakes domains.</li>
<li><strong>Regulatory Lag:</strong> Voluntary codes insufficient.</li>
<li><strong>Ethical Responsibility:</strong> Developers must anticipate societal impact.</li>
</ul>


<div class="section-title">5. Next Steps</div>
<ul>
<li>Confirm November 16 logistics.</li>
<li>Share symposium details and invite topic suggestions.</li>
<li>Continue exploring governance frameworks and safeguards.</li>
</ul>
</tr>

</table>

</body>
</html>
