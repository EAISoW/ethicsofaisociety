<!DOCTYPE html>
<html>
<head>
    <title>Ethics of AI Society of Waterloo</title>

    <style>
        body {
            background-color: #232A44;
            color: white;
            font-family: Arial, sans-serif;
            text-align: left;
        }

        a {
            color: #A9C7FF;
        }

        table {
    width: 40%;
    border-collapse: collapse;
}

td, th {
    border: 1px solid #ccc;
    padding: 10px;
    vertical-align: top;
}

th {
    background-color: #000000;
    text-align: left;
}

.section-header {
    background-color: #cc0000;
    font-weight: bold;
    font-size: 1.1em;
}

.meta {
    background-color: #232A44;
}

ul {
    margin-top: 5px;
}
</style>
   
</head>

<body>
<center>

<a href="https://eaisow.github.io/ethicsofaisociety/">
    <img src="images/eais.png" width="700"></center>
</a>
    
    

    <p>
Previous Meetings
    </p>


</head>

<body>

<table>

<tr>
<h1>Meeting Overview</h1>

<div class="meta">
<p>
<strong>Date & Time:</strong> October 28, 2025, 8:02 PM<br>
<strong>Facilitator:</strong> Matthew Steven William Silk<br>
<strong>Main Topics:</strong><br>
AI in medicine and therapy<br>
AI literacy and policy<br>
Ethical concerns around AI use<br>
Superintelligence and trust<br>
Upcoming symposium planning
</p>
</div>


<div class="section-title">Key Discussion Points</div>

<div class="subsection-title">1. AI Literacy and Policy Developments</div>
<ul>
<li>MPP Rob Surgenek expressed interest in AI ethics and literacy initiatives in secondary and elementary education.</li>
<li>University of Waterloo involvement in federal AI task forces raised concerns about prioritizing economic growth over ethics.</li>
<li>Critical Media Lab published a skeptical article on GenAI in education, highlighting campus tensions between adoption and caution.</li>
</ul>


<div class="subsection-title">2. AI in Medicine</div>

<p><strong>Applications:</strong></p>
<ul>
<li>Diagnostic support (e.g., GPT-4 diagnosing complex cases).</li>
<li>Administrative efficiency (note-taking, logistics).</li>
</ul>

<p><strong>Concerns:</strong></p>
<ul>
<li>Hallucinations in medical records.</li>
<li>Data labeling errors (e.g., misdiagnosis based on irrelevant image features).</li>
<li>Lack of domain expertise in data preparation.</li>
<li>Trust and transparency in AI-generated decisions.</li>
</ul>


<div class="subsection-title">3. AI in Therapy</div>
<ul>
<li>Increasing use of ChatGPT as therapeutic support, especially where access to care is limited.</li>
</ul>

<p><strong>Risks identified:</strong></p>
<ul>
<li>Reinforcement of false beliefs.</li>
<li>Deceptive empathy and sycophantic responses.</li>
<li>Inadequate crisis management.</li>
<li>Potential “AI psychosis” (e.g., users believing divine communication).</li>
</ul>

<p><strong>Ethical dilemma:</strong> AI may offer temporary relief but lacks depth, responsibility, and accountability of human therapists.</p>


<div class="subsection-title">4. Superintelligence and Trust</div>

<ul>
<li>Debate over artificial superintelligence and anthropomorphizing AI.</li>
<li>Risks of deference to AI in high-stakes environments (medicine, law).</li>
<li>AI as black box undermining public science and transparency.</li>
<li>Examples such as AlphaFold illustrate powerful but opaque systems.</li>
</ul>

<p><strong>Philosophical concerns:</strong></p>
<ul>
<li>Can AI make promises or apologies?</li>
<li>Is AI testimony trustworthy?</li>
<li>What constitutes intelligence and intent in machines?</li>
</ul>


<div class="subsection-title">5. Ethical Implications of Removing AI Filters</div>
<ul>
<li>Discussion of potential removal of adult content filters.</li>
<li>Risks of increased sexualization and gambling addiction.</li>
<li>Questions about age verification and societal impact.</li>
<li>Observation that AI exposes hidden societal issues, prompting discussion.</li>
</ul>


<div class="section-title">Symposium Planning</div>
<ul>
<li>Poster and GoFundMe launched.</li>
<li>Potential keynote: Jeffrey Hinton (via Crystal and others).</li>
<li>Date: Tentatively Winter 2026, pending coordination with Laurier.</li>
</ul>


<div class="section-title">Next Meeting</div>
<ul>
<li><strong>Date:</strong> November 11, 2025</li>
<li><strong>Topics:</strong>
    <ul>
        <li>AI, testimony, and trust</li>
        <li>Defining superintelligence</li>
        <li>Human brain organoids and ethical implications (presentation by Patrick)</li>
    </ul>
</li>
</ul>
</tr>

</table>

</body>
</html>
