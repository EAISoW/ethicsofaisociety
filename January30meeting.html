<!DOCTYPE html>
<html>
<head>
    <title>Ethics of AI Society of Waterloo</title>

    <style>
        body {
            background-color: #232A44;
            color: white;
            font-family: Arial, sans-serif;
            text-align: left;
        }

        a {
            color: #A9C7FF;
        }

        table {
    width: 40%;
    border-collapse: collapse;
}

td, th {
    border: 1px solid #ccc;
    padding: 10px;
    vertical-align: top;
}

th {
    background-color: #000000;
    text-align: left;
}

.section-header {
    background-color: #cc0000;
    font-weight: bold;
    font-size: 1.1em;
}

.meta {
    background-color: #232A44;
}

ul {
    margin-top: 5px;
}
</style>
   
</head>

<body>
<center>

<a href="https://eaisow.github.io/ethicsofaisociety/">
    <img src="images/eais.png" width="700"></center>
</a>
    
    

    <p>
Previous Meetings
    </p>


</head>

<body>

<table>

<tr>
  <h1>Briefing Notes – Ethics of AI Society Meeting</h1>

<div class="meta">
<p>
<strong>Date:</strong> January 30, 2026<br>
<strong>Location:</strong> University of Waterloo<br>
<strong>Chair:</strong> Matthew Steven William Silk<br>
<strong>Topic Focus:</strong> Peircean Epistemology & AI; Symposium Updates; Introductions; Future Topics
</p>
</div>

<div class="section">
<div class="numbered-title">1. Administrative Updates</div>

<h3>Symposium Planning</h3>
<ul>
<li>Funding raised through donations; additional funds welcomed via GoFundMe.</li>
<li>Goal: Provide refreshments and potentially secure a keynote speaker.</li>
<li>Estimated 7 presentation slots; ~5 confirmed presenters.</li>
<li>Seeking participants from Laurier, especially philosophy faculty or students.</li>
<li>
Presentations:
    <ul>
        <li>20-minute talk + 10-minute Q&A</li>
        <li>Slides permitted</li>
        <li>Recordings available on request</li>
    </ul>
</li>
</ul>

<h3>Teams Group Access</h3>
<ul>
<li>New members encouraged to ensure access.</li>
<li>Contact Matthew for troubleshooting.</li>
</ul>
</div>

<div class="section">
<div class="numbered-title">2. Introductions</div>

<p>A diverse group across Waterloo and Laurier attended, including:</p>

<ul>
<li>Philosophy instructors</li>
<li>Undergraduate/graduate students</li>
<li>Professionals in AI ethics, research, engineering, data science</li>
<li>Returning members and new participants</li>
</ul>

<p><strong>Notable expertise:</strong></p>
<ul>
<li><strong>Ian MacDonald</strong> – specialist in Charles Sanders Peirce</li>
<li><strong>Patrick Matlock</strong> – built ML model to transcribe Peirce’s handwriting (81% accuracy)</li>
</ul>
</div>

<div class="section">
<div class="numbered-title">3. Main Discussion: AI, Peirce, and Inquiry</div>

<h3>3.1 Background: Peirce’s Theory of Signs</h3>
<p><strong>Presented by Ian MacDonald</strong></p>

<p>Peirce distinguishes three sign types:</p>
<ul>
<li><strong>Icons</strong> – resemble their object</li>
<li><strong>Indices</strong> – physically connected to their object</li>
<li><strong>Symbols</strong> – conventional representations (e.g., words)</li>
</ul>

<p>AI primarily manipulates <strong>symbols</strong>, lacking robust handling of <strong>indices</strong> or <strong>icons</strong>, limiting grounding in real-world meaning.</p>

<h3>3.2 Peirce’s View of Inquiry</h3>
<p>Key elements:</p>
<ul>
<li>Inquiry moves from <strong>doubt</strong> to <strong>belief</strong>.</li>
<li>Beliefs inform <strong>habits</strong> → influence <strong>practices</strong>.</li>
<li>Meaning determined by the <strong>conceivable practical effects</strong> of a concept.</li>
<li>Humans possess <strong>real-world contact</strong>; AI does not.</li>
</ul>

<h3>3.3 Issues Raised with Respect to AI</h3>

<p><strong>(1) Lack of Real-World Grounding</strong></p>
<ul>
<li>Statistical understanding, not embodied experience.</li>
<li>Cannot test ideas against reality.</li>
</ul>

<p><strong>(2) Logical Fragility / Hallucinations</strong></p>
<ul>
<li>Produces contradictions or impossible answers.</li>
<li>No internal grasp of logical laws.</li>
</ul>

<p><strong>(3) Coherence vs. Correspondence</strong></p>
<ul>
<li>AI resembles coherence theory of truth.</li>
<li>Humans rely on pragmatic/external correspondence.</li>
</ul>

<p><strong>(4) Inductive Scaling</strong></p>
<ul>
<li>Mass statistical induction.</li>
<li>Lacks real-world resistance to hypotheses.</li>
</ul>
</div>

<div class="section">
<div class="numbered-title">4. Counterpoints & Technical Discussions</div>

<h3>4.1 Can AI Be Made More Logical or Grounded?</h3>
<ul>
<li>Logic-checking modules on top of LLMs.</li>
<li>Sensory-input robotic models.</li>
<li>Reinforcement learning as weak external check.</li>
</ul>

<h3>4.2 Patrick’s Contributions</h3>
<ul>
<li>Chain-of-thought workflows enhance reliability.</li>
<li>World-modeling approaches (e.g., Yann LeCun).</li>
<li>Classifying training data by epistemic status.</li>
</ul>

<h3>4.3 Limits of Current AI</h3>
<ul>
<li>No qualitative experience (qualia).</li>
<li>Understanding bounded by dataset.</li>
<li>Humans form novel, non-statistical thoughts.</li>
<li>True grounding requires continuous embodied sensory streams.</li>
</ul>

<h3>4.4 Hybrid Intelligence</h3>
<ul>
<li>Combine human inquiry with AI pattern recognition.</li>
<li>AI as concept-mapper, assistant, replication tool.</li>
</ul>
</div>

<div class="section">
<div class="numbered-title">5. Application to Research Practice</div>

<h3>5.1 AI as a Tool in Academic Inquiry</h3>
<ul>
<li>Unreliable for specific claims/testimony.</li>
<li>Useful for:
    <ul>
        <li>Mapping conceptual connections</li>
        <li>Processing large datasets</li>
        <li>Routine or replication-heavy tasks</li>
    </ul>
</li>
<li>Human oversight essential.</li>
</ul>

<h3>5.2 Concerns About Over-Automation</h3>
<ul>
<li>Loss of human purpose in research.</li>
<li>Homogenization of thought.</li>
<li>Erosion of creativity.</li>
<li>Potential increased creativity if routine work automated.</li>
</ul>
</div>

<div class="section">
<div class="numbered-title">6. Topic Suggestions for Future Meetings</div>

<ul>
<li>AI, privacy, & medical data</li>
<li>AI in warfare</li>
<li>AI hallucinations and testimony</li>
<li>Ethical issues in data scraping</li>
<li>Bias and big-tech accountability</li>
<li>Healthcare AI applications (e.g., mammography)</li>
</ul>

<p>Matthew will circulate reading materials.</p>
</div>

<div class="section">
<div class="numbered-title">7. Next Meeting</div>

<p>
<strong>Proposed Date:</strong> Friday, February 13, 2026<br>
<strong>Location:</strong> Same room (if available)<br>
<strong>Time:</strong> Evening session<br>
Matthew to confirm booking and share article beforehand.
</p>
</div>
</tr>

</table>

</body>
</html>
