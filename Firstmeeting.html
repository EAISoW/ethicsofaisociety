<!DOCTYPE html>
<html>
<head>
    <title>Ethics of AI Society of Waterloo</title>

    <style>
        body {
            background-color: #232A44;
            color: white;
            font-family: Arial, sans-serif;
            text-align: left;
        }

        a {
            color: #A9C7FF;
        }

        table {
    width: 40%;
    border-collapse: collapse;
}

td, th {
    border: 1px solid #ccc;
    padding: 10px;
    vertical-align: top;
}

th {
    background-color: #000000;
    text-align: left;
}

.section-header {
    background-color: #cc0000;
    font-weight: bold;
    font-size: 1.1em;
}

.meta {
    background-color: #232A44;
}

ul {
    margin-top: 5px;
}
</style>
   
</head>

<body>
<center>

<a href="https://eaisow.github.io/ethicsofaisociety/">
    <img src="images/eais.png" width="700"></center>
</a>
    
    

    <p>
Previous Meetings
    </p>


</head>

<body>

<table>

<tr>
<h1>Briefing Notes – First AI Ethics Discussion Group Meeting</h1>

<div class="meta">
<p>
<strong>Date:</strong> October 5, 2023<br>
<strong>Duration:</strong> 1h 16m<br>
<strong>Facilitator:</strong> Dr. Matthew Silk<br>
<strong>Participants:</strong> Students and faculty from multiple disciplines (philosophy, data science, political science, legal studies, sociology, business, etc.)
</p>
</div>

<div class="section-title">1. Purpose of the Meeting</div>
<ul>
<li>Create an interdisciplinary space to discuss ethical, social, and practical implications of AI.</li>
<li>Explore diverse perspectives beyond technical considerations.</li>
<li>Identify shared concerns (bias, accountability, transparency, democracy, future of work).</li>
</ul>


<div class="section-title">2. Introductions & Participant Interests</div>

<p><strong>Key themes emerging from introductions:</strong></p>

<p><strong>a. AI, Bias, and Data Ethics</strong></p>
<ul>
<li>Concern about uncritical trust in data (“data doesn't lie” mindset).</li>
<li>Need to interrogate data origins, interpretation, and social context.</li>
<li>Anxiety around ML systems shaping hiring, sentencing, and public policy.</li>
</ul>

<p><strong>b. Ethics of Belief & Misinformation</strong></p>
<ul>
<li>AI shaping beliefs, sometimes incorrectly.</li>
<li>Students relying on generative AI may harm their own learning and focus.</li>
<li>Algorithms increasingly treated as unquestioned authorities.</li>
</ul>

<p><strong>c. AI in Law and Professional Practice</strong></p>
<ul>
<li>Potential for AI to replace paralegals or assist lawyers.</li>
<li>Difficulty incorporating emotion, nuance, contextual reasoning.</li>
<li>Risks of hallucinated legal summaries or fabricated case references.</li>
</ul>

<p><strong>d. Democracy, Surveillance & Platform Power</strong></p>
<ul>
<li>Social media algorithms shape political views and reinforce echo chambers.</li>
<li>Concerns about censorship, biased filtering, and manipulation.</li>
<li>Fear that algorithmic feeds narrow worldviews.</li>
</ul>

<p><strong>e. Cultural & Global Equity Concerns</strong></p>
<ul>
<li>Models reflect dominant Western/white/Christian/male assumptions.</li>
<li>Poor representation of African languages and histories.</li>
<li>Risk of erasing minority cultures and knowledge systems.</li>
</ul>

<p><strong>f. Future of Work & Human Creativity</strong></p>
<ul>
<li>Anxiety that heavy AI use undermines genuine skill development.</li>
<li>Human output may converge toward “algorithmic norms.”</li>
<li>Fear of accelerating job displacement and loss of purpose.</li>
</ul>


<div class="section-title">3. Core Discussion Themes</div>

<p><strong>A. Generative AI in Writing & Education</strong></p>

<p><strong>Concerns raised:</strong></p>
<ul>
<li>Students tempted to use AI for assignments, undermining learning.</li>
<li>AI-produced content often generic or incorrect.</li>
<li>Detection tools (Turnitin, GPT detectors) unreliable and potentially harmful.</li>
<li>Overreliance erodes student confidence.</li>
</ul>

<p><strong>Potential benefits (cautiously acknowledged):</strong></p>
<ul>
<li>Help with phrasing, idea testing, formatting.</li>
<li>Brainstorming partner (“asking a person on the street”).</li>
</ul>

<p><strong>Proposed responses from educators:</strong></p>
<ul>
<li>Shift focus from final product to writing process.</li>
<li>Require disclosure of AI use.</li>
<li>Design assignments requiring complex synthesis.</li>
<li>Increase seminar-style learning (resource-intensive).</li>
</ul>


<p><strong>B. Reliability & Hallucination in AI Systems</strong></p>
<ul>
<li>Contradictory claims about historical events (e.g., Vietnam War).</li>
<li>Fabricated citations and legal cases.</li>
<li>Falsehoods presented confidently as truth.</li>
</ul>

<p><strong>Ethical implication:</strong><br>
→ Encourages blind trust, undermines critical reasoning, and risks real-world harm.
</p>


<p><strong>C. Algorithmic Bias & Structural Discrimination</strong></p>
<ul>
<li>Facial recognition misidentifying marginalized individuals.</li>
<li>North American/colonial training dominance reproducing inequalities.</li>
<li>Translation failures for non-Western languages.</li>
<li>Historical erasure of colonized or oppressed populations.</li>
</ul>

<p><strong>Conclusion:</strong> AI risks amplifying racial, colonial, and patriarchal bias unless fundamentally restructured.</p>


<p><strong>D. Capitalism, Power, and Dependence on AI</strong></p>
<ul>
<li>Tech companies incentivized to maximize dependency.</li>
<li>Data collection fuels attention economy.</li>
<li>Acceleration of inequality and elite power consolidation.</li>
<li>AI becoming “necessary infrastructure.”</li>
</ul>


<p><strong>E. Human Cognition, Memory & Autonomy</strong></p>
<ul>
<li>Tool reliance reduces memory and problem-solving capacity.</li>
<li>Cognitive dependence on AI for basic thinking.</li>
<li>Risk of AI shaping beliefs and identities via personal assistants.</li>
</ul>


<div class="section-title">4. Key Risks Identified</div>
<ul>
<li>Erosion of critical thinking</li>
<li>Hallucinated information influencing decisions</li>
<li>Bias and discrimination embedded in models</li>
<li>Worsening inequality and cultural erasure</li>
<li>Loss of student skills and independence</li>
<li>Opaque algorithmic authority replacing human judgment</li>
<li>Capitalist incentives overriding ethics</li>
</ul>


<div class="section-title">5. Potential Benefits (When Used Carefully)</div>
<ul>
<li>Brainstorming assistance</li>
<li>Formatting help</li>
<li>Reducing cognitive load</li>
<li>Creative idea generation</li>
<li>Organizing information and summarization</li>
<li>Accessibility support</li>
</ul>

<p>These benefits remain conditional on transparency, critical evaluation, and context.</p>


<div class="section-title">6. Closing & Next Steps</div>
<ul>
<li>Interest in continued meetings.</li>
<li>Preference for later-week sessions.</li>
<li>
Proposal to:
    <ul>
        <li>Circulate an article before each meeting.</li>
        <li>Encourage material sharing via Teams.</li>
        <li>Continue exploring themes (AI & law, decolonizing AI, education, political algorithms, etc.).</li>
    </ul>
</li>
</ul>
</tr>

</table>

</body>
</html>
